{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAE(predicted,actual):\n",
    "    AE = np.sum(np.abs(actual-predicted))\n",
    "    MAE = AE/len(predicted)\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(training_path):\n",
    "    trn_all = pd.read_csv(training_path)\n",
    "    index=list(trn_all)\n",
    "    #my_indices = [0,1,2,3,5,6,7,9,10,15,17, 18, 23]\n",
    "    #my_indices = [0,1,2,3,7,11,15,19,23]\n",
    "    my_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "    trn_new = trn_all[[index[i] for i in my_indices]]\n",
    "    trn_new = trn_new[trn_new['Expected']<69]\n",
    "\n",
    "    #combine observations with same ID by using mean\n",
    "    trn_mean = trn_new.groupby(trn_new.Id).agg(['mean', 'median', 'std', 'count','min','max','skew', 'mad'])\n",
    "    trn_mean.columns = ['_'.join(col).strip() for col in trn_mean.columns.values]\n",
    "    # ignore id's where all Ref vales are NaN\n",
    "    trn_mean = trn_mean[pd.notnull(trn_mean.Ref_mean)]\n",
    "\n",
    "    # replace missing values by mean\n",
    "    index2 = list(trn_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    trn_mean= pd.DataFrame(imp.fit_transform(trn_mean),index = trn_mean.index, columns=index2)\n",
    "\n",
    "    #train and test data preparation\n",
    "    y_trn = np.log1p(trn_mean.loc[:,'Expected_mean'].values)\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Zdr_5x5_90th_count'].values\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_count'].values\n",
    "    X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_mad'].values\n",
    "    unique_ID = trn_mean.index.tolist()\n",
    "    return X_trn, y_trn,unique_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data_for_testing(training_path):\n",
    "    trn_all = pd.read_csv(training_path)\n",
    "    index=list(trn_all)\n",
    "    my_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "    trn_new = trn_all[[index[i] for i in my_indices]]\n",
    "\n",
    "    #combine observations with same ID by using mean\n",
    "    trn_mean = trn_new.groupby(trn_new.Id).agg(['mean', 'median', 'std', 'count','min','max','skew', 'mad'])\n",
    "    trn_mean.columns = ['_'.join(col).strip() for col in trn_mean.columns.values]\n",
    "    # ignore id's where all Ref vales are NaN\n",
    "    trn_mean = trn_mean[pd.notnull(trn_mean.Ref_mean)]\n",
    "\n",
    "    # replace missing values by mean\n",
    "    index2 = list(trn_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    trn_mean= pd.DataFrame(imp.fit_transform(trn_mean),index = trn_mean.index, columns=index2)\n",
    "\n",
    "    #train and test data preparation\n",
    "    y_trn = np.log1p(trn_mean.loc[:,'Expected_mean'].values)\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Zdr_5x5_90th_count'].values\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_count'].values\n",
    "    X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_mad'].values\n",
    "    unique_ID = trn_mean.index.tolist()\n",
    "    return X_trn, y_trn,unique_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_testing_data(testing_path):\n",
    "    test_all = pd.read_csv(testing_path)\n",
    "    index=list(test_all)\n",
    "    # my_indices = [0,1,2,3,5,6,7,9,10,15,17, 18]\n",
    "    #my_indices = [0,1,2,3,7,11,15,19]\n",
    "    my_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "    test_new = test_all[[index[i] for i in my_indices]]\n",
    "    test_mean = test_new.groupby(test_new.Id).agg(['mean', 'median', 'std', 'count','min','max','skew', 'mad'])\n",
    "    test_mean.columns = ['_'.join(col).strip() for col in test_mean.columns.values]\n",
    "\n",
    "    # Imputing with mean values\n",
    "    index2 = list(test_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    test_mean= pd.DataFrame(imp.fit_transform(test_mean),index=test_mean.index,columns=index2)\n",
    "    #test_X = test_mean.loc[:,'minutes_past_mean':'Zdr_5x5_90th_count'].values\n",
    "    #test_X = test_mean.loc[:,'minutes_past_mean':'Kdp_count'].values\n",
    "    test_X = test_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_mad'].values\n",
    "    unique_ID = test_mean.index.tolist()\n",
    "    return test_X,unique_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_submission_pure(ID_list,prediction,out_file):\n",
    "\n",
    "    test_result = pd.DataFrame()\n",
    "    print(len(ID_list))\n",
    "    print(len(prediction))\n",
    "    test_result['Id'] = ID_list\n",
    "    test_result['Expected'] = prediction\n",
    "    test_result.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    num_round = 200 # Number of boosted trees\n",
    "    param = {}\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 4\n",
    "    param['bst:max_depth'] = 5\n",
    "    param['bst:eta'] = 0.3\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['min_child_weight'] = 1\n",
    "    param['gamma'] = 0\n",
    "    param['max_delta_step'] = 0\n",
    "    param['subsample'] = 1\n",
    "    param['colsample_bytree'] = 1\n",
    "\n",
    "    print('Loading training data')\n",
    "    X_trn, y_trn,trn_ID = get_training_data('../data/train.csv')\n",
    "    print('Done loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('Training data with Max Absolute Error')\n",
    "    xgmat = xgb.DMatrix(X_trn, label=y_trn)\n",
    "    plst = param.items()\n",
    "    watchlist = []\n",
    "    t = time.time()\n",
    "    bst = xgb.train(plst, xgmat, num_round, watchlist)\n",
    "    print(time.time()-t)\n",
    "    print('Done training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('Prediction for training data')\n",
    "    \n",
    "    num_round = 200 # Number of boosted trees\n",
    "    param = {}\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 4\n",
    "    param['bst:max_depth'] = 5\n",
    "    param['bst:eta'] = 0.3\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['min_child_weight'] = 1\n",
    "    param['gamma'] = 0\n",
    "    param['max_delta_step'] = 0\n",
    "    param['subsample'] = 1\n",
    "    param['colsample_bytree'] = 1\n",
    "\n",
    "    print('Loading training data')\n",
    "    X_trn, y_trn,trn_ID = get_training_data_for_testing('../data/train.csv')\n",
    "    print('Done loading')\n",
    "    tmp_predict = bst.predict(xgmat)\n",
    "    trn_predict = np.exp(tmp_predict)-1\n",
    "    print('Done prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('Prediction for testing data')\n",
    "    X_test,test_ID  = get_testing_data('../data/test.csv')\n",
    "    xgmat_test = xgb.DMatrix(X_test)\n",
    "    tmp_predict = bst.predict(xgmat_test)\n",
    "    test_predict = np.exp(tmp_predict)-1\n",
    "    print('Done prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('Writing the submission file')\n",
    "    out_file = '../data/xgb_result_v5_pure_allFeatures_train_skew.csv'\n",
    "    export_submission_pure(trn_ID,trn_predict,out_file)\n",
    "    out_file = '../data/xgb_result_v5_pure_allFeatures_test_skew.csv'\n",
    "    export_submission_pure(test_ID,test_predict,out_file)\n",
    "    print('Done writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
