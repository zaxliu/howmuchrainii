{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    num_round = 200 # Number of boosted trees\n",
    "    param = {}\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 4\n",
    "    param['bst:max_depth'] = 5\n",
    "    param['bst:eta'] = 0.3\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['min_child_weight'] = 1\n",
    "    param['gamma'] = 0\n",
    "    param['max_delta_step'] = 0\n",
    "    param['subsample'] = 1\n",
    "    param['colsample_bytree'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    print('Loading training data')\n",
    "    #X_trn, y_trn,trn_ID = get_training_data('../data/train.csv')\n",
    "    trn_all = pd.read_csv('../data/train.csv')\n",
    "    index=list(trn_all)\n",
    "    #my_indices = [0,1,2,3,5,6,7,9,10,15,17, 18, 23]\n",
    "    #my_indices = [0,1,2,3,7,11,15,19,23]\n",
    "    my_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "    trn_new = trn_all[[index[i] for i in my_indices]]\n",
    "    trn_new = trn_new[trn_new['Expected']<69]\n",
    "\n",
    "    #combine observations with same ID by using mean\n",
    "    trn_mean = trn_new.groupby(trn_new.Id).agg(['mean', 'median', 'std', 'count','min','max'])\n",
    "    trn_mean.columns = ['_'.join(col).strip() for col in trn_mean.columns.values]\n",
    "    # ignore id's where all Ref vales are NaN\n",
    "    trn_mean = trn_mean[pd.notnull(trn_mean.Ref_mean)]\n",
    "\n",
    "    # replace missing values by mean\n",
    "    index2 = list(trn_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    trn_mean= pd.DataFrame(imp.fit_transform(trn_mean),index = trn_mean.index, columns=index2)\n",
    "\n",
    "    #train and test data preparation\n",
    "    y_trn = np.log1p(trn_mean.loc[:,'Expected_mean'].values)\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Zdr_5x5_90th_count'].values\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_count'].values\n",
    "    X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_max'].values\n",
    "    trn_ID = trn_mean.index.tolist()\n",
    "    print('Done loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data with Max Absolute Error\n",
      "783.886269093\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "    print('Training data with Max Absolute Error')\n",
    "    xgmat = xgb.DMatrix(X_trn, label=y_trn)\n",
    "    plst = param.items()\n",
    "    watchlist = []\n",
    "    t = time.time()\n",
    "    bst = xgb.train(plst, xgmat, num_round, watchlist)\n",
    "    print(time.time()-t)\n",
    "    print('Done training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print('Prediction for training data')\n",
    "\n",
    "    print('Loading training data')\n",
    "    trn_all = pd.read_csv('../data/train.csv')\n",
    "    index=list(trn_all)\n",
    "    my_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "    trn_new = trn_all[[index[i] for i in my_indices]]\n",
    "\n",
    "    #combine observations with same ID by using mean\n",
    "    trn_mean = trn_new.groupby(trn_new.Id).agg(['mean', 'median', 'std', 'count','min','max'])\n",
    "    trn_mean.columns = ['_'.join(col).strip() for col in trn_mean.columns.values]\n",
    "    # ignore id's where all Ref vales are NaN\n",
    "    trn_mean = trn_mean[pd.notnull(trn_mean.Ref_mean)]\n",
    "\n",
    "    # replace missing values by mean\n",
    "    index2 = list(trn_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    trn_mean= pd.DataFrame(imp.fit_transform(trn_mean),index = trn_mean.index, columns=index2)\n",
    "\n",
    "    #train and test data preparation\n",
    "    y_trn = np.log1p(trn_mean.loc[:,'Expected_mean'].values)\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Zdr_5x5_90th_count'].values\n",
    "    #X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_count'].values\n",
    "    X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_max'].values\n",
    "    trn_ID = trn_mean.index.tolist()\n",
    "    \n",
    "    print('Done loading')\n",
    "    tmp_predict = bst.predict(xgmat)\n",
    "    trn_predict = np.exp(tmp_predict)-1\n",
    "    print('Done prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print('Prediction for testing data')\n",
    "    test_all = pd.read_csv('../data/test.csv')\n",
    "    index=list(test_all)\n",
    "    # my_indices = [0,1,2,3,5,6,7,9,10,15,17, 18]\n",
    "    #my_indices = [0,1,2,3,7,11,15,19]\n",
    "    my_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "    test_new = test_all[[index[i] for i in my_indices]]\n",
    "    test_mean = test_new.groupby(test_new.Id).agg(['mean', 'median', 'std', 'count','min','max'])\n",
    "    test_mean.columns = ['_'.join(col).strip() for col in test_mean.columns.values]\n",
    "\n",
    "    # Imputing with mean values\n",
    "    index2 = list(test_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    test_mean= pd.DataFrame(imp.fit_transform(test_mean),index=test_mean.index,columns=index2)\n",
    "    #test_X = test_mean.loc[:,'minutes_past_mean':'Zdr_5x5_90th_count'].values\n",
    "    #test_X = test_mean.loc[:,'minutes_past_mean':'Kdp_count'].values\n",
    "    test_X = test_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_max'].values\n",
    "    test_ID = test_mean.index.tolist()\n",
    "    xgmat_test = xgb.DMatrix(test_X)\n",
    "    tmp_predict = bst.predict(xgmat_test)\n",
    "    test_predict = np.exp(tmp_predict)-1\n",
    "    print('Done prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('Writing the train file')\n",
    "    out_file = '../data/xgb_result_v5_pure_allFeatures_train.csv'\n",
    "    test_result = pd.DataFrame()\n",
    "    test_result['Id'] = trn_ID\n",
    "    test_result['Expected'] = trn_predict\n",
    "    test_result.to_csv(out_file, index=False)\n",
    "    print('Done writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('Writing the test file')\n",
    "    out_file = '../data/xgb_result_v5_pure_allFeatures_test.csv'\n",
    "    test_result = pd.DataFrame()\n",
    "    test_result['Id'] = test_ID\n",
    "    test_result['Expected'] = test_predict\n",
    "    test_result.to_csv(out_file, index=False)\n",
    "    print('Done writing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
