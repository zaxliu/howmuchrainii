{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "def MAE(predicted,actual):\n",
    "    AE = np.sum(np.abs(actual-predicted))\n",
    "    MAE = AE/len(predicted)\n",
    "    return MAE\n",
    "\n",
    "def get_training_data(training_path):\n",
    "    trn_all = pd.read_csv(training_path)\n",
    "\n",
    "    trn_new = trn_all[trn_all['Expected']<69]\n",
    "\n",
    "    #combine observations with same ID by using mean\n",
    "    trn_mean = trn_new.groupby(trn_new.Id).agg(['mean', 'median', 'std', 'count','min','max'])\n",
    "    trn_mean.columns = ['_'.join(col).strip() for col in trn_mean.columns.values]\n",
    "    #trn_mean = trn_mean.drop(['Expected_count', 'Expected_median', 'Expected_std','Expected_min','Expected_max'], axis =1)\n",
    "    #print(trn_mean)\n",
    "    # ignore id's where all Ref vales are NaN\n",
    "    trn_mean = trn_mean[pd.notnull(trn_mean.Ref_mean)]\n",
    "\n",
    "    # replace missing values by mean\n",
    "    index2 = list(trn_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    trn_mean= pd.DataFrame(imp.fit_transform(trn_mean),index = trn_mean.index, columns=index2)\n",
    "\n",
    "    #train and test data preparation\n",
    "    y_trn = np.log1p(trn_mean.loc[:,'Expected_mean'].values)\n",
    "\n",
    "    X_trn = trn_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_max'].values\n",
    "\n",
    "    #print(X_trn)\n",
    "\n",
    "    return X_trn, y_trn\n",
    "\n",
    "def get_testing_data(testing_path):\n",
    "    test_new = pd.read_csv(testing_path)\n",
    "   \n",
    "    test_mean = test_new.groupby(test_new.Id).agg(['mean', 'median', 'std', 'count','min','max'])\n",
    "    test_mean.columns = ['_'.join(col).strip() for col in test_mean.columns.values]\n",
    "\n",
    "    # Imputing with mean values\n",
    "    index2 = list(test_mean)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    test_mean= pd.DataFrame(imp.fit_transform(test_mean),index=test_mean.index,columns=index2)\n",
    "\n",
    "    test_X = test_mean.loc[:,'minutes_past_mean':'Kdp_5x5_90th_max'].values\n",
    "    unique_ID = pd.unique(test_new['Id'])\n",
    "\n",
    "    return test_X,test_mean,unique_ID\n",
    "\n",
    "def xgb_cv(X_trn, y_trn, objective, num_folds, num_threads, num_round, eta, max_depth, min_child_weight,max_delta_step, gamma,subsample,colsample):\n",
    "\n",
    "\n",
    "    param = {}\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = num_threads\n",
    "    param['bst:max_depth'] = max_depth\n",
    "    param['bst:eta'] = eta\n",
    "    param['objective'] = objective\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "    param['gamma'] = gamma\n",
    "    param['max_delta_step'] = max_delta_step\n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample\n",
    "    #param['eval_metric'] = 'mae' --- how to self design\n",
    "\n",
    "    '''\n",
    "    Cross validation for XGBoost performance with MAE\n",
    "    '''\n",
    "\n",
    "    best_model = None\n",
    "    kf = cv.KFold(len(y_trn), n_folds=num_folds)\n",
    "    accu = 0\n",
    "\n",
    "    for train_indices, test_indices in kf:\n",
    "\n",
    "        xgb_train_cv, xgb_test_cv = X_trn[train_indices], X_trn[test_indices]\n",
    "        y_train_cv, y_test_cv = y_trn[train_indices], y_trn[test_indices]\n",
    "\n",
    "        xgmat = xgb.DMatrix(xgb_train_cv, label=y_train_cv)\n",
    "        plst = param.items()\n",
    "        watchlist = []#[(xgmat, 'train')] #evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "\n",
    "        t = time.time()\n",
    "        bst = xgb.train(plst, xgmat, num_round, watchlist)\n",
    "        print(time.time()-t)\n",
    "\n",
    "        xgmat_test = xgb.DMatrix(xgb_test_cv)\n",
    "        tmp_predict = bst.predict(xgmat_test)\n",
    "        y_predict = np.exp(tmp_predict)-1\n",
    "        accu = accu+ MAE(y_predict,y_test_cv)\n",
    "\n",
    "    return accu/num_folds\n",
    "\n",
    "def export_submission(unique_ID,prediction,processed_test,out_file):\n",
    "\n",
    "    marshall = pd.read_csv('../data/MP_r_09.csv')\n",
    "    test_result_exist = pd.DataFrame()\n",
    "    test_result_exist['Id'] = processed_test.index\n",
    "    test_result_exist['Expected'] = prediction\n",
    "\n",
    "    test_result = pd.DataFrame()\n",
    "    test_result['Id'] = unique_ID\n",
    "    test_result = pd.merge(test_result, test_result_exist, how='left', on=['Id'], sort=True)\n",
    "    #test_result.loc[test_result['Expected'].isnull(), 'Expected'] = marshall.loc[test_result['Expected'].isnull(), 'Expected']\n",
    "    test_result.loc[test_result['Expected'].notnull(), 'Expected'] = 0.75*test_result.loc[test_result['Expected'].notnull(), 'Expected']+0.25*marshall.loc[test_result['Expected'].notnull(), 'Expected']\n",
    "\n",
    "    test_result.to_csv(out_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "\n",
    "    # setup parameters for xgboost\n",
    "\n",
    "    #XGB default\n",
    "    #eta [default=0.3]: step size shrinkage\n",
    "    #gamma [default=0]: minimum loss reduction\n",
    "    #max_depth [default=6]\n",
    "    #min_child_weight [default=1]\n",
    "    #max_delta_step [default=0]\n",
    "    #subsample [default=1]\n",
    "    #colsample_bytree [default=1]\n",
    "    #lambda [default=1]: L2 regularization\n",
    "    #alpha [default=0]: L1 regularization\n",
    "\n",
    "objective = 'reg:linear'\n",
    "num_round = 10 # Number of boosted trees\n",
    "\n",
    "num_folds = 3\n",
    "num_threads = 4\n",
    "eta = 0.3\n",
    "max_depth = 5\n",
    "min_child_weight = 1\n",
    "max_delta_step = 0\n",
    "gamma = 0\n",
    "subsample = 1\n",
    "colsample = 1\n",
    "\n",
    "print('Loading training data')\n",
    "X_trn, y_trn = get_training_data('../data/train.csv')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data with cross validation on Max Absolute Error\n",
      "25.1383960247\n",
      "25.0252101421\n",
      "25.0842449665\n"
     ]
    }
   ],
   "source": [
    "print('Training data with cross validation on Max Absolute Error')\n",
    "\n",
    "#cross-validation: eta, max_depth, gamma\n",
    "    \n",
    "accu = xgb_cv(X_trn, y_trn, objective, num_folds, num_threads, num_round, eta, max_depth, min_child_weight, max_delta_step,gamma,subsample ,colsample)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction with the best validation model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_valid_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0149947906c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprocessed_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munique_ID\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mget_testing_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mxgmat_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtmp_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_valid_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgmat_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mxgb_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_valid_model' is not defined"
     ]
    }
   ],
   "source": [
    "print('Prediction with the best validation model')\n",
    "X_test,processed_test,unique_ID  = get_testing_data('../data/test.csv')\n",
    "xgmat_test = xgb.DMatrix(X_test)\n",
    "tmp_predict = best_valid_model.predict(xgmat_test)\n",
    "xgb_predict = np.exp(tmp_predict)-1\n",
    "\n",
    "    # print(len(xgb_predict))\n",
    "    # print(len(unique_ID))\n",
    "\n",
    "print('Writing the submission file')\n",
    "out_file = '../data/xgb_result_v5_pure_allFeatures_2.csv'\n",
    "export_submission(unique_ID,xgb_predict,processed_test, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
