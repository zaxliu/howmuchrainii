{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "from sklearn.learning_curve import learning_curve, validation_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "#\n",
    "import xgboost as xgb\n",
    "#\n",
    "from blending import BlendedRegressor\n",
    "from cleaning import TargetThresholdFilter, LogPlusOne\n",
    "#\n",
    "pd.set_option('display.max_columns', 500)  # force pandas to display all columns for better visual inspection\n",
    "# plot plots inline\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dataset IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read training set into memory\n",
    "trn = pd.read_csv('../data/train.csv')\n",
    "# trn_10 = pd.read_csv('../data/train_10.csv', index_col=0)  # column #0 in our file is index\n",
    "# trn_1 = pd.read_csv('../data/train_1.csv', index_col=0)\n",
    "\n",
    "# reading the MP values for training data\n",
    "# MP_train = pd.read_csv('../data/MP_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.3495 secs\n",
      "(13765201, 24) (6349375, 24) 731556 1180945\n"
     ]
    }
   ],
   "source": [
    "t = time.time()  # tic\n",
    "## filter out observations with non-valid 'Ref'\n",
    "# trn_1_withRef = trn_1[trn_1['Ref'].notnull()]\n",
    "# trn_10_withRef = trn_10[trn_10['Ref'].notnull()]\n",
    "trn_withRef = trn[trn['Ref'].notnull()]\n",
    "print 'Time elapsed: {:.4f} secs'.format(time.time()-t)  # toc\n",
    "## dimension checking\n",
    "# print trn_1.shape, trn_1_withRef.shape, trn_1_withRef['Id'].nunique(), trn_1['Id'].nunique()\n",
    "# print trn_10.shape, trn_10_withRef.shape, trn_10_withRef['Id'].nunique(), trn_10['Id'].nunique()\n",
    "print trn.shape, trn_withRef.shape, trn_withRef['Id'].nunique(), trn['Id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Combine observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9870300293\n"
     ]
    }
   ],
   "source": [
    "# Combine observations by 'Id'\n",
    "t = time.time()\n",
    "# trn_withRef_comb = trn_withRef.groupby('Id').agg(np.mean)\n",
    "trn_withRef_comb = trn_withRef.groupby('Id').agg(['mean','std','median','count','min', 'max'])\n",
    "trn_withRef_comb.columns = ['_'.join(tup) for (i,tup) in enumerate(trn_withRef_comb.columns.values)]\n",
    "trn_withRef_comb = trn_withRef_comb.drop(['Expected_count', 'Expected_median', 'Expected_std', 'Expected_min','Expected_max'], axis =1)\n",
    "# trn_withRef_comb.columns = ['_'.join(tup) for tup in trn_withRef_comb.columns.values]\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'minutes_past_mean', u'minutes_past_std', u'minutes_past_median',\n",
       "       u'minutes_past_count', u'minutes_past_min', u'minutes_past_max',\n",
       "       u'radardist_km_mean', u'radardist_km_std', u'radardist_km_median',\n",
       "       u'radardist_km_count',\n",
       "       ...\n",
       "       u'Kdp_5x5_50th_count', u'Kdp_5x5_50th_min', u'Kdp_5x5_50th_max',\n",
       "       u'Kdp_5x5_90th_mean', u'Kdp_5x5_90th_std', u'Kdp_5x5_90th_median',\n",
       "       u'Kdp_5x5_90th_count', u'Kdp_5x5_90th_min', u'Kdp_5x5_90th_max',\n",
       "       u'Expected_mean'],\n",
       "      dtype='object', length=133)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_withRef_comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MP_09 = MP_train.loc[MP_train['Id'].isin(trn_withRef_comb.index)]\n",
    "# MP_09.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truth = trn_withRef_comb['Expected_mean']\n",
    "# mp = MP_09['Expected']\n",
    "# diff = truth-mp\n",
    "# log_diff = np.log10(100+diff)\n",
    "# print truth.min(), truth.median(), truth.max()\n",
    "# print mp.min(), mp.median(), mp.max()\n",
    "# print diff.min(), diff.median(), diff.max()\n",
    "# print np.percentile(diff, [1, 10, 50, 90, 95])\n",
    "# tmp = tmp + np.min(tmp)\n",
    "# print tmp.min(), tmp.median(), tmp.max()\n",
    "# tmp = tmp/np.median(tmp)\n",
    "# diff.hist(bins=100)\n",
    "# plt.xlim([-100, 100])\n",
    "# np.sum(tmp.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Form feature X and target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract matrix-form data from pandas df\n",
    "X = trn_withRef_comb.loc[:, 'minutes_past_mean':'Kdp_5x5_90th_max']  # NOTE: used range slicing on column\n",
    "# y = np.log10(trn_withRef_comb['Expected'].values)  # y = log(Truth)\n",
    "y = np.log10(1+trn_withRef_comb['Expected_mean'])  # y = log(1+Truth)\n",
    "# y = (trn_withRef_comb['Expected']-MP_09['Expected']).values  # y = Truth-MP\n",
    "# y = np.log10(1+trn_withRef_comb['Expected']-MP_09['Expected']).values  # y = log(100+Truth-MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'minutes_past_mean', u'minutes_past_std', u'minutes_past_median',\n",
       "       u'minutes_past_count', u'minutes_past_min', u'minutes_past_max',\n",
       "       u'radardist_km_mean', u'radardist_km_std', u'radardist_km_median',\n",
       "       u'radardist_km_count',\n",
       "       ...\n",
       "       u'Kdp_5x5_50th_median', u'Kdp_5x5_50th_count', u'Kdp_5x5_50th_min',\n",
       "       u'Kdp_5x5_50th_max', u'Kdp_5x5_90th_mean', u'Kdp_5x5_90th_std',\n",
       "       u'Kdp_5x5_90th_median', u'Kdp_5x5_90th_count', u'Kdp_5x5_90th_min',\n",
       "       u'Kdp_5x5_90th_max'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MAE_logy(ground_truth, predictions):\n",
    "    \"\"\"Custom scoring function for log(y) or log(1+y)\n",
    "       NOTE: please change this if you use another non-linearity on y\n",
    "    \"\"\"\n",
    "    return np.float64(np.mean(np.abs(10**ground_truth - 10**predictions)))\n",
    "def MAE(ground_truth, predictions):\n",
    "    \"\"\"Standard MAE\n",
    "    \"\"\"\n",
    "    return np.float64(np.mean(np.abs(ground_truth - predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 ML and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Constuct pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ttf = TargetThresholdFilter(threshold=np.log10(1+200))\n",
    "imp = Imputer(strategy='mean')  # Get a imputor with column-mean filling config\n",
    "ss = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "base1 = RandomForestRegressor(n_estimators=800, max_features='sqrt', max_depth=5, n_jobs=6)  # NOTE: n_jobs=-1 will use all of your cores, set to a prefered number e.g. 4\n",
    "# base2 = LinearRegression()\n",
    "# base3 = Ridge()\n",
    "# blender = LinearRegression()\n",
    "# blended = BlendedRegressor(base_models=(base1, base2, base3), blending_model=blender, blending_split=10)\n",
    "pip = Pipeline([('imp',imp), ('ss',ss), ('clf', base1)])  # a Pipeline wrapper to chain'em up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2A: Single param value cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 39.5min finished\n"
     ]
    }
   ],
   "source": [
    "scorer = make_scorer(MAE_logy, greater_is_better=True)  # define scoring metric\n",
    "scores = cross_val_score(estimator=pip, X=X, y=y, scoring=scorer, cv=10, n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2716100202 1.57705091824\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# Filter-out null ref, !!!log(Truth)!!!, impute with mean, (0,1) standardization, RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3509680762 1.57723658976\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean], Filter-out null ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization, RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.170990758 7.72976027985\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, cnt], all feature, include ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization, RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2697228078 1.5791936134\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt]\n",
    "# Filter-out null ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization\n",
    "# RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.1995830031 1.57656296034\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# Filter-out null ref, !!!Truth-MP!!!, impute with mean, (0,1) standardization, RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.1906870356 1.55649221847\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# Filter-out null ref, !!!log(100+Truth-MP)!!!, impute with mean, (0,1) standardization, RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3129628677 1.57943826265\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature\n",
    "# Filter-out null ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization\n",
    "# RF with 10 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2679013424 1.58035973259\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature\n",
    "# Filter-out null ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization\n",
    "# RF with 100 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2672901319 1.58032760699\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature\n",
    "# Filter-out null ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization\n",
    "# RF with 400 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2672901319 1.58032760699\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature\n",
    "# Filter-out null ref, !!!log(1+Truth)!!!, impute with mean, (0,1) standardization\n",
    "# RF with 800 trees, 'sqrt' features, depth=5\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different base model combinitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2223155559 1.58094899068\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature, \n",
    "# Filter-out null ref, log(1+Truth), impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression]; blender: linear regression\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2210455962 1.58214249794\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature, \n",
    "# Filter-out null ref, log(1+Truth), impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender: linear regression\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2747272334 1.58051217883\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature, \n",
    "# Filter-out null ref, log(1+Truth), fitler-out > 20 in training set, impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender: linear regression\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2708855142 1.58166060195\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt],, all feature, \n",
    "# Filter-out null ref, log(1+Truth), fitler-out > 80 in training set, impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender: linear regression\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.28848374 1.58172934802\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt], all feature, \n",
    "# Filter-out null ref, log(1+Truth), fitler-out > 200 in training set, impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender: linear regression\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different blender models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.092708538 1.74175693759\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt], all feature, \n",
    "# Filter-out null ref, log(1+Truth), impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender: DecisionTreeRegressor()\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2445810224 1.58433463038\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt], all feature, \n",
    "# Filter-out null ref, log(1+Truth), impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender:  RandomForestRegressor(n_estimators=10, max_features='sqrt', max_depth=2)\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.4272316965 1.53517827948\n"
     ]
    }
   ],
   "source": [
    "# Scores:\n",
    "# [mean, med, std, min, max, cnt], all feature, \n",
    "# Filter-out null ref, log(1+Truth), impute with mean, (0,1) standardization, \n",
    "# Blending: base: [RF with 10 tree, 'sqrt' features, depth=5], [linear regression], [ridge]; blender:  KNN()\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2B: Validation curve on list of single param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(MAE_logy, greater_is_better=True)  # define scoring metric\n",
    "param_name, param_range='clf__n_estimators', [2**i for i in range(4, 9)]\n",
    "# param_name, param_range= 'clf__max_depth', range(1, 20, 2)\n",
    "train_scores, test_scores= validation_curve(estimator=pip, X=X, y=y, scoring=scorer, cv=10, n_jobs=2, \n",
    "                          param_name=param_name, param_range=param_range, verbose=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: Filter-out null-ref samples, log(1+y), impute with mean, (0,1) standardization, RF with [2**i for i in range(4, 9)] trees, 'sqrt' features, max_depth=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_scores_mean, train_scores_std, test_scores_mean, test_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the validation curver, i.e. trn/val error versus parameter value\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(param_name)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
