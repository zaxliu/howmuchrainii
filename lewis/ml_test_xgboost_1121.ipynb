{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "from sklearn.learning_curve import learning_curve, validation_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "#\n",
    "import xgboost as xgb\n",
    "#\n",
    "from blending import BlendedRegressor\n",
    "from cleaning import TargetThresholdFilter, LogPlusOne\n",
    "#\n",
    "pd.set_option('display.max_columns', 500)  # force pandas to display all columns for better visual inspection\n",
    "# plot plots inline\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn = pd.read_csv('../data/train.csv')\n",
    "# trn = pd.read_csv('../data/train_10.csv', index_col=0)  # column #0 in our file is DataFrame index\n",
    "# trn = pd.read_csv('../data/train_1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.3542 secs\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "trn_withRef = trn[trn['Ref'].notnull()]\n",
    "print 'Time elapsed: {:.4f} secs'.format(time.time()-t)  # toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 7.0609 secs\n"
     ]
    }
   ],
   "source": [
    "# Combine observations by 'Id', aggregate features\n",
    "t = time.time()\n",
    "trn_withRef_comb = trn_withRef.groupby('Id').agg(['mean','std','median','count','min', 'max'])\n",
    "trn_withRef_comb.columns = ['_'.join(tup) for (i,tup) in enumerate(trn_withRef_comb.columns.values)]\n",
    "trn_withRef_comb = trn_withRef_comb.drop(['Expected_count', 'Expected_median', 'Expected_std', 'Expected_min','Expected_max'], axis =1)\n",
    "print 'Time elapsed: {:.4f} secs'.format(time.time()-t)  # toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = trn_withRef_comb.loc[:, 'minutes_past_mean':'Kdp_5x5_90th_max']  # NOTE: used range slicing on column\n",
    "y = trn_withRef_comb['Expected_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttf = TargetThresholdFilter(threshold=np.inf)\n",
    "lpo = LogPlusOne()\n",
    "imp = Imputer(strategy='median', copy=False)  # Get a imputor with column-mean filling config\n",
    "ss = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "clf = xgb.sklearn.XGBRegressor(n_estimators=500, nthread=5, max_depth=5, learning_rate=0.3)\n",
    "pip = Pipeline([('ttf',ttf), ('lpo',lpo), ('imp',imp), ('ss',ss), ('clf',clf)])  # a Pipeline wrapper to chain'em up\n",
    "def LogPlusOne_score(ground_truth, predictions, lpo=lpo):\n",
    "    return np.float64(np.mean(np.abs(ground_truth - (np.power(10, predictions) - 1))))\n",
    "scorer = make_scorer(LogPlusOne_score, greater_is_better=True)  # define scoring metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 71.8min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pip, X=X, y=y, scoring=scorer, cv=10, n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.1870628005 1.5801378357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 46.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Pipeline(steps=[\n",
    "# ('imp', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0))\n",
    "# ('ss', StandardScaler(copy=False, with_mean=True, with_std=True)), \n",
    "# ('clf', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#       min_child_weight=1, missing=None, n_estimators=500, nthread=5,\n",
    "#       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#       scale_pos_weight=1, seed=0, silent=True, subsample=1))])\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2120059037 1.55426425433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf': XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "        learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "        min_child_weight=1, missing=None, n_estimators=500, nthread=5,\n",
       "        objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "        scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       " 'clf__base_score': 0.5,\n",
       " 'clf__colsample_bylevel': 1,\n",
       " 'clf__colsample_bytree': 1,\n",
       " 'clf__gamma': 0,\n",
       " 'clf__learning_rate': 0.3,\n",
       " 'clf__max_delta_step': 0,\n",
       " 'clf__max_depth': 5,\n",
       " 'clf__min_child_weight': 1,\n",
       " 'clf__missing': None,\n",
       " 'clf__n_estimators': 500,\n",
       " 'clf__nthread': 5,\n",
       " 'clf__objective': 'reg:linear',\n",
       " 'clf__reg_alpha': 0,\n",
       " 'clf__reg_lambda': 1,\n",
       " 'clf__scale_pos_weight': 1,\n",
       " 'clf__seed': 0,\n",
       " 'clf__silent': True,\n",
       " 'clf__subsample': 1,\n",
       " 'imp': Imputer(axis=0, copy=False, missing_values='NaN', strategy='median',\n",
       "     verbose=0),\n",
       " 'imp__axis': 0,\n",
       " 'imp__copy': False,\n",
       " 'imp__missing_values': 'NaN',\n",
       " 'imp__strategy': 'median',\n",
       " 'imp__verbose': 0,\n",
       " 'lpo': LogPlusOne(),\n",
       " 'ss': StandardScaler(copy=False, with_mean=True, with_std=True),\n",
       " 'ss__copy': False,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'steps': [('ttf', TargetThresholdFilter(threshold=inf)),\n",
       "  ('lpo', LogPlusOne()),\n",
       "  ('imp', Imputer(axis=0, copy=False, missing_values='NaN', strategy='median',\n",
       "       verbose=0)),\n",
       "  ('ss', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "          learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "          min_child_weight=1, missing=None, n_estimators=500, nthread=5,\n",
       "          objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "          scale_pos_weight=1, seed=0, silent=True, subsample=1))],\n",
       " 'ttf': TargetThresholdFilter(threshold=inf),\n",
       " 'ttf__threshold': inf}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print np.mean(scores), np.std(scores)\n",
    "pip.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ttf', TargetThresholdFilter(threshold=inf)), ('lpo', LogPlusOne()), ('imp', Imputer(axis=0, copy=False, missing_values='NaN', strategy='median',\n",
       "    verbose=0)), ('ss', StandardScaler(copy=False, with_mean=True, with_std=True)), ('clf', XGBRegressor(base_score=0.5, colsample_bylevel=1, cols...g:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "test_withRef = test[test['Ref'].notnull()]\n",
    "test_withRef_comb = test_withRef.groupby('Id').agg(['mean','std','median','count','min', 'max'])\n",
    "test_withRef_comb.columns = ['_'.join(tup) for (i,tup) in enumerate(test_withRef_comb.columns.values)]\n",
    "test_X = test_withRef_comb.loc[:, 'minutes_past_mean':'Kdp_5x5_90th_max']  # NOTE: used range slicing on column\n",
    "test_y_predict = 10**pip.predict(X=test_X)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/result_20151122_102648.csv\n"
     ]
    }
   ],
   "source": [
    "# Ref-samples\n",
    "test_result_withRef = pd.DataFrame()\n",
    "test_result_withRef['Id'] = test_withRef_comb.index\n",
    "test_result_withRef['Expected'] = test_y_predict\n",
    "# All-samples\n",
    "test_result = pd.DataFrame()\n",
    "test_result['Id'] = test['Id'].unique()\n",
    "# Merge and set Non-Ref samples to -1\n",
    "test_result = pd.merge(test_result, test_result_withRef, how='left', on=['Id'], sort=True)\n",
    "test_result.loc[test_result['Expected'].isnull(), 'Expected'] = -1\n",
    "# Write file\n",
    "datetime_str = time.strftime('%Y%m%d_%H%M%S')\n",
    "test_result.to_csv('../data/result_'+datetime_str+'.csv', index=False)\n",
    "print '../data/result_'+datetime_str+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
